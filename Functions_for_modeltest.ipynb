{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import odeint \n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pylab as py\n",
    "from math import *\n",
    "import numpy as np\n",
    "from scipy.optimize import newton\n",
    "from matplotlib import animation, rc\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from IPython.display import HTML\n",
    "\n",
    "import warnings\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differential equations describing the system\n",
    "def double_pendulum(u,t,m1,m2,L1,L2,g):\n",
    "    # du = derivatives\n",
    "    # u = variables\n",
    "    # p = parameters\n",
    "    # t = time variable\n",
    "\n",
    "    du = np.zeros(4)\n",
    "    c = np.cos(u[0]-u[2])  # intermediate variables\n",
    "    s = np.sin(u[0]-u[2])  # intermediate variables\n",
    "\n",
    "    du[0] = u[1]   # d(theta 1)\n",
    "    du[1] = ( m2*g*np.sin(u[2])*c - m2*s*(L1*c*u[1]**2 + L2*u[3]**2) - (m1+m2)*g*np.sin(u[0]) ) /( L1 *(m1+m2*s**2) )\n",
    "    du[2] = u[3]   # d(theta 2)\n",
    "    du[3] = ((m1+m2)*(L1*u[1]**2*s - g*np.sin(u[2]) + g*np.sin(u[0])*c) + m2*L2*u[3]**2*s*c) / (L2 * (m1 + m2*s**2))\n",
    "\n",
    "    return du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inout_sequences(input_data, tw):\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L-tw):\n",
    "        train_seq = input_data[i:i+tw]\n",
    "        train_label = input_data[i+tw:i+tw+1]\n",
    "        inout_seq.append((train_seq ,train_label))\n",
    "    return inout_seq\n",
    "\n",
    "def preprocess_sol(train_data_normalized, train_window):\n",
    "    train_inout_seq= create_inout_sequences(train_data_normalized.reshape(len(train_data_normalized), 9), train_window)\n",
    "    return train_inout_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makepath_param(theta1, theta2, m1,m2,l1,l2, g = 9.81):\n",
    "    u0 = [np.pi*theta1/180, 0, np.pi*theta2/180, 0]\n",
    "    tfinal = 125.0 \n",
    "    Nt = 3755\n",
    "    #timesteps\n",
    "    dt = tfinal / Nt\n",
    "    \n",
    "    t = np.linspace(0, tfinal, Nt)\n",
    "    sol = odeint(double_pendulum, u0, t, args=(m1,m2,l1,l2,g))\n",
    "    \n",
    "    # add parameter in columns\n",
    "    params = np.array([m1, m2, l1, l2, dt])\n",
    "    \n",
    "    # repeat params along the length of the simulation\n",
    "    params_repeated = np.tile(params, (sol.shape[0], 1))\n",
    "    \n",
    "    # stack it on the simulation\n",
    "    sol_with_params = np.hstack((sol, params_repeated))\n",
    "    \n",
    "    return sol_with_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_simulations(theta1, theta2, change_of_angle, amount_of_different_inits, m1_params, m2_params, l1_params, l2_params, g):\n",
    "    simulation_sets = []\n",
    "    #This slope is defined for different initial condition\n",
    "    for i in range(0, amount_of_different_inits):\n",
    "        theta1 += change_of_angle\n",
    "        theta2 -= change_of_angle\n",
    "        print(f\"theta 1 ist {theta1}\")\n",
    "        print(f\"theta 2 ist {theta2}\")\n",
    "        for m1 in m1_params:\n",
    "            for m2 in m2_params:\n",
    "                for l1 in l1_params:\n",
    "                    for l2 in l2_params:\n",
    "                        sol = makepath_param(theta1, theta2, m1,m2,l1,l2,g)\n",
    "                        print(f\"m1 = {m1}; l1 = {l1}; m2 = {m2}; l2 = {l2}\\n\")\n",
    "                        simulation_sets.append(sol)\n",
    "    return simulation_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_splitter_and_scaler(scaler, Simulation_datasets, test_size = 0.2):\n",
    "    train_splits = []\n",
    "    test_splits = []\n",
    "\n",
    "    for dataset in Simulation_datasets:\n",
    "        split_index = int(len(dataset) * (1 - test_size))\n",
    "        train_split = dataset[:split_index]\n",
    "        test_split = dataset[split_index:]\n",
    "        train_splits.append(train_split)\n",
    "        test_splits.append(test_split)\n",
    "    \n",
    "    for i in range(len(train_splits)):\n",
    "        dataset = train_splits[i]\n",
    "        train_window = 10\n",
    "        \n",
    "        #separating the params since those valuus shouldnt be scale\n",
    "        params_and_dt = dataset[:, 4:]\n",
    "        m1, m2, l1, l2, dt = params_and_dt[0]\n",
    "        print(f\"m1 = {m1}; l1 = {l1}; m2 = {m2}; l2 = {l2}; dt = {dt}\\n\")\n",
    "        \n",
    "        train_data_normalized = scaler.fit_transform(dataset[:, :4].reshape(-1, 4))\n",
    "        train_data_normalized_with_params = np.concatenate((train_data_normalized, params_and_dt), axis=1)    \n",
    "        train_data_normalized_with_params = torch.FloatTensor(train_data_normalized_with_params).reshape(len(dataset), 9)\n",
    "\n",
    "        #A change of the reshape function inside the preprocess_sol might be required in case you change the amount of timesteps\n",
    "        train_inout_seq = preprocess_sol(train_data_normalized_with_params, train_window)\n",
    "        \n",
    "        train_splits[i] = train_inout_seq\n",
    "        \n",
    "    return train_splits, test_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_calculation(theta1, theta2, theta1_dot, theta2_dot, mass1=2.0, mass2=1.0, length1=1.4, length2=1.0, g=9.81):\n",
    "\n",
    "    kinetic_energy = 0.5 * mass1 * length1**2 * theta1_dot**2 + 0.5 * mass2 * ((length1 * theta1_dot)**2 + (length2 * theta2_dot)**2 + 2 * length1 * length2 * theta1_dot * theta2_dot * np.cos(theta1 - theta2))\n",
    "\n",
    "    potential_energy = -mass1 * g * length1 * np.cos(theta1) - mass2 * g * (length1 * np.cos(theta1) + length2 * np.cos(theta2))\n",
    "\n",
    "    total_energy = abs(kinetic_energy + potential_energy)\n",
    "\n",
    "    return total_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the full OneStep function.   it\n",
    "def OneStep(model, model_layers, data, filename, filepath_excel, steps = 100, g = 9.81):\n",
    "    print('data set length =', len(data))\n",
    "    train_window = 10\n",
    "    initial_predict_data = data[:, :4]\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    train_data_normalized = scaler.fit_transform(initial_predict_data.reshape(-1, 4))\n",
    "    fut_pred = len(data) -train_window\n",
    "    test_inputs = train_data_normalized[0:train_window].reshape(train_window,4).tolist()\n",
    "    #print(test_inputs)\n",
    "    # s2 = train_data_normalized.reshape(len(data),4).tolist()\n",
    "    realdata = data\n",
    "    model.eval().cpu()\n",
    "    preds = test_inputs.copy()\n",
    "    t2 = test_inputs\n",
    "    hidden_layer_size = 100\n",
    "    x = 0\n",
    "    for i in range(fut_pred):\n",
    "        seq = torch.FloatTensor(t2[i:]).cpu()\n",
    "        model.c_h = (torch.zeros(model_layers, 1, hidden_layer_size),\n",
    "                        torch.zeros(model_layers, 1, hidden_layer_size))\n",
    "        x = model(seq).cpu()\n",
    "        x = x.cpu()\n",
    "        preds.append(x.detach().numpy())\n",
    "        t2.append(x.detach().numpy())\n",
    "    actual_predictions = scaler.inverse_transform(np.array(preds ).reshape(-1,4))\n",
    "    print(len(actual_predictions))\n",
    "\n",
    "    # the following will plot the lower mass path for steps using the actual ODE sover\n",
    "    # and the predicitons\n",
    "    plt.figure( figsize=(10,5))\n",
    "    u0 = data[:,0]     # theta_1\n",
    "    u1 = data[:,1]     # omega 1\n",
    "    u2 = data[:,2]     # theta_2\n",
    "    u3 = data[:,3]     # omega_2\n",
    "    up0 = actual_predictions[:,0]     # theta_1\n",
    "    up1 = actual_predictions[:,1]     # omega 1\n",
    "    up2 = actual_predictions[:,2]     # theta_2\n",
    "    up3 = actual_predictions[:,3]     # omega_2\n",
    "    m1 = data[:, 4][0]\n",
    "    m2 = data[:, 5][0]\n",
    "    l1 = data[:, 6][0]\n",
    "    l2 = data[:, 7][0]\n",
    "    x1 = l1*np.sin(u0);          # First Pendulum\n",
    "    y1 = -l1*np.cos(u0);\n",
    "    x2 = x1 + l2*np.sin(u2);     # Second Pendulum\n",
    "    y2 = y1 - l2*np.cos(u2);\n",
    "    xp1 = l1*np.sin(up0);          # First Pendulum\n",
    "    yp1 = -l1*np.cos(up0);\n",
    "    xp2 = xp1 + l2*np.sin(up2);     # Second Pendulum\n",
    "    yp2 = yp1 - l2*np.cos(up2); \n",
    "    print(x2[0], y2[0])\n",
    "    plt.plot(x2[0:steps], y2[0:steps], color='r')\n",
    "    plt.plot(xp2[0:steps],yp2[0:steps] , color='g')\n",
    "\n",
    "    ###############################################################################\n",
    "    dt = data[:, 8][0]\n",
    "    Nt = len(data[:, 8])\n",
    "    tfinal = dt * Nt\n",
    "    t = np.linspace(0, tfinal, Nt)\n",
    "\n",
    "    energy_data = energy_calculation(u0, u2, u1, u3, m1, m2, l1, l2)\n",
    "    energy_predicted = energy_calculation(up0, up2, up1, up3, m1, m2, l1, l2)\n",
    "\n",
    "    ###############################################################################\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ## Only necessary when addapting the lookback\n",
    "    # lookback += 200\n",
    "    plt.suptitle('Simulation vs Prediction - ' + filename, fontsize=16)\n",
    "\n",
    "    lookback = 0\n",
    "    plt.subplot(3, 2, 1)\n",
    "    plt.plot(t[lookback:], data[lookback:, 0], label='Simulation')\n",
    "    plt.plot(t[lookback:], actual_predictions[:, 0], label='Prediction')\n",
    "    plt.ylabel('Theta 1')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(3, 2, 2)\n",
    "    plt.plot(t[lookback:], data[lookback:, 1], label='Simulation')\n",
    "    plt.plot(t[lookback:], actual_predictions[:, 1], label='Prediction')\n",
    "    plt.ylabel('Omega 1')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(3, 2, 3)\n",
    "    plt.plot(t[lookback:], data[lookback:, 2], label='Simulation')\n",
    "    plt.plot(t[lookback:], actual_predictions[:, 2], label='Prediction')\n",
    "    plt.ylabel('Theta 2')\n",
    "    plt.xlabel('Time in s')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(3, 2, 4)\n",
    "    plt.plot(t[lookback:], data[lookback:, 3], label='Simulation')\n",
    "    plt.plot(t[lookback:], actual_predictions[:, 3], label='Prediction')\n",
    "    plt.ylabel('Omega 2')\n",
    "    plt.xlabel('Time in s')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(3, 2, 5)\n",
    "    plt.plot(t[lookback:], energy_data, label='Simulation')\n",
    "    plt.plot(t[lookback:], energy_predicted, label='Prediction')\n",
    "    plt.ylabel('Omega 2')\n",
    "    plt.xlabel('Time in s')\n",
    "    plt.legend()\n",
    "\n",
    "    ##############################################################################\n",
    "    \n",
    "    # Create dataframe\n",
    "    df = pd.DataFrame({ 'time': t,\n",
    "        f'theta1_actual': data[:, 0], 'omega1_actual': data[:, 1],\n",
    "        'theta2_actual': data[:, 2], 'omega2_actual': data[:, 3],\n",
    "        'energy_actual': energy_data,\n",
    "        'm1': data[:, 4], 'm2': data[:, 5], 'l1': data[:, 6], 'l2': data[:, 7], 'dt': data[:, 8],\n",
    "        'theta1_predicted': actual_predictions[:, 0], 'omega1_predicted': actual_predictions[:, 1],\n",
    "        'theta2_predicted': actual_predictions[:, 2], 'omega2_predicted': actual_predictions[:, 3],\n",
    "        'energy_predicted': energy_predicted,\n",
    "    })\n",
    "\n",
    "    #Combination filepath and filename\n",
    "    full_path = os.path.join(filepath_excel, filename)\n",
    "\n",
    "    # safe csv\n",
    "    df.to_csv(f'{full_path}.csv', index=False)\n",
    "    \n",
    "    return actual_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positions(theta1, theta2, length1, length2):\n",
    "    x1 = length1 * np.sin(theta1)\n",
    "    y1 = -length1 * np.cos(theta1)\n",
    "    x2 = x1 + length2 * np.sin(theta2)\n",
    "    y2 = y1 - length2 * np.cos(theta2)\n",
    "    return x1, y1, x2, y2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
